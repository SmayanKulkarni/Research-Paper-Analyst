{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb76bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GROQ_API_KEY=\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1795765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LiteLLM is not available, falling back to LiteLLM\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Fallback to LiteLLM is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, Task, Crew, LLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize Large Language Model (LLM) of your choice (see all models on our Models page)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroq/llama-3.1-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create your CrewAI agents with role, main goal/objective, and backstory/personality\u001b[39;00m\n\u001b[1;32m      7\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m      8\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentation Summarizer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Agent's job title/function\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreate concise summaries of technical documentation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Agent's main objective\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# Show agent's thought process as it completes its task\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/AI-ML-DS/AI-and-ML-Course/.conda/lib/python3.11/site-packages/crewai/llm.py:400\u001b[0m, in \u001b[0;36mLLM.__new__\u001b[0;34m(cls, model, is_litellm, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LITELLM_AVAILABLE:\n\u001b[1;32m    399\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiteLLM is not available, falling back to LiteLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFallback to LiteLLM is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    402\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28msuper\u001b[39m(LLM, instance)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, is_litellm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mImportError\u001b[0m: Fallback to LiteLLM is not available"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# Initialize Large Language Model (LLM) of your choice (see all models on our Models page)\n",
    "llm = LLM(model=\"groq/llama-3.1-70b-versatile\")\n",
    "\n",
    "# Create your CrewAI agents with role, main goal/objective, and backstory/personality\n",
    "summarizer = Agent(\n",
    "    role='Documentation Summarizer', # Agent's job title/function\n",
    "    goal='Create concise summaries of technical documentation', # Agent's main objective\n",
    "    backstory='Technical writer who excels at simplifying complex concepts', # Agent's background/expertise\n",
    "    llm=llm, # LLM that powers your agent\n",
    "    verbose=True # Show agent's thought process as it completes its task\n",
    ")\n",
    "\n",
    "translator = Agent(\n",
    "    role='Technical Translator',\n",
    "    goal='Translate technical documentation to other languages',\n",
    "    backstory='Technical translator specializing in software documentation',\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Define your agents' tasks\n",
    "summary_task = Task(\n",
    "    description='Summarize this React hook documentation:\\n\\nuseFetch(url) is a custom hook for making HTTP requests. It returns { data, loading, error } and automatically handles loading states.',\n",
    "    expected_output=\"A clear, concise summary of the hook's functionality\",\n",
    "    agent=summarizer # Agent assigned to task\n",
    ")\n",
    "\n",
    "translation_task = Task(\n",
    "    description='Translate the summary to Turkish',\n",
    "    expected_output=\"Turkish translation of the hook documentation\",\n",
    "    agent=translator,\n",
    "    dependencies=[summary_task] # Must run after the summary task\n",
    ")\n",
    "\n",
    "# Create crew to manage agents and task workflow\n",
    "crew = Crew(\n",
    "    agents=[summarizer, translator], # Agents to include in your crew\n",
    "    tasks=[summary_task, translation_task], # Tasks in execution order\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4a385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "paper_id = \"2511.20636\"\n",
    "url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/related-papers?fields=title,abstract,url\"\n",
    "\n",
    "response = requests.get(url).json()\n",
    "\n",
    "for p in response.get(\"data\", []):\n",
    "    print(p[\"score\"], p[\"paper\"][\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a818c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Paper with id 2511.20636/related-papers not found'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smayan/Desktop/AI-ML-DS/AI-and-ML-Course/.conda/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "2025-11-26 16:41:09.769100: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 16:41:09.899044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764155469.945200   12882 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764155469.958731   12882 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764155470.068679   12882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764155470.068692   12882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764155470.068693   12882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764155470.068693   12882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-26 16:41:10.080163: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37b3726130340199efbecf2ac5dc3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64df6607bbbf44d282ea38ea78e10058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8547bfca70d6432fa80d56b2a5f64718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee5b07e02064c3fa17573fd131792bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d30315779744509c96a930c6d3b4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9993291e5148c5bda1efc35e0cbd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77fd2998a764473b053984f3fdfaa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ab188dbfa9404688f1fec3e82008c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7c0d9cc8814b05b9f9b18a0534f6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68058c097974ba7bfd06e7ab797b8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0adee190dc41528522b4c909215741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12882/2036739176.py:10: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  paper = list(search.results())[0]\n",
      "/tmp/ipykernel_12882/2036739176.py:23: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for r in results.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar papers:\n",
      "0.4052 - ShapeGlot: Learning Language for Shape Differentiation (http://arxiv.org/abs/1905.02925v1)\n",
      "0.3416 - Intelligent requirements engineering from natural language and their chaining toward CAD models (http://arxiv.org/abs/2007.07825v1)\n",
      "0.3105 - Listening while Speaking and Visualizing: Improving ASR through Multimodal Chain (http://arxiv.org/abs/1906.00579v3)\n",
      "0.2871 - Hierarchical Decision Making by Generating and Following Natural Language Instructions (http://arxiv.org/abs/1906.00744v5)\n",
      "0.2846 - A Study on Effects of Implicit and Explicit Language Model Information for DBLSTM-CTC Based Handwriting Recognition (http://arxiv.org/abs/2008.01532v1)\n",
      "0.2744 - The Go Transformer: Natural Language Modeling for Game Play (http://arxiv.org/abs/2007.03500v3)\n",
      "0.2595 - Applying GPGPU to Recurrent Neural Network Language Model based Fast Network Search in the Real-Time LVCSR (http://arxiv.org/abs/2007.11794v1)\n",
      "0.2560 - DQI: A Guide to Benchmark Evaluation (http://arxiv.org/abs/2008.03964v1)\n",
      "0.2448 - From Words to Sentences: A Progressive Learning Approach for Zero-resource Machine Translation with Visual Pivots (http://arxiv.org/abs/1906.00872v1)\n",
      "0.2404 - Unsupervised Text Generation by Learning from Search (http://arxiv.org/abs/2007.08557v1)\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Load an embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Get abstract of a given paper\n",
    "paper_id = \"2511.20636\"  # example\n",
    "search = arxiv.Search(id_list=[paper_id])\n",
    "paper = list(search.results())[0]\n",
    "target_abstract = paper.summary\n",
    "\n",
    "# 3. Encode the target paper\n",
    "target_emb = model.encode(target_abstract, convert_to_tensor=True)\n",
    "\n",
    "# 4. Search for candidate papers in the same category\n",
    "search_query = \"cat:cs.CL\"  # choose your category\n",
    "results = arxiv.Search(query=search_query, max_results=200)\n",
    "\n",
    "candidate_papers = []\n",
    "candidate_abstracts = []\n",
    "\n",
    "for r in results.results():\n",
    "    if r.entry_id.endswith(paper_id):\n",
    "        continue\n",
    "    candidate_papers.append(r)\n",
    "    candidate_abstracts.append(r.summary)\n",
    "\n",
    "# 5. Encode candidate abstracts\n",
    "candidate_embs = model.encode(candidate_abstracts, convert_to_tensor=True)\n",
    "\n",
    "# 6. Compute similarities\n",
    "cos_scores = util.cos_sim(target_emb, candidate_embs)[0]\n",
    "\n",
    "# 7. Get top-k similar papers\n",
    "top_k = 10\n",
    "top_results = cos_scores.topk(top_k)\n",
    "\n",
    "print(\"Top similar papers:\")\n",
    "for score, idx in zip(top_results.values, top_results.indices):\n",
    "    p = candidate_papers[idx]\n",
    "    print(f\"{score:.4f} - {p.title} ({p.entry_id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12882/3682888443.py:21: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  paper = list(search.results())[0]\n",
      "/tmp/ipykernel_12882/3682888443.py:38: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for r in results.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar papers:\n",
      "\n",
      "0.4052 - ShapeGlot: Learning Language for Shape Differentiation (http://arxiv.org/abs/1905.02925v1)\n",
      "  Downloading to: downloads/1905.02925v1.pdf\n",
      "0.3416 - Intelligent requirements engineering from natural language and their chaining toward CAD models (http://arxiv.org/abs/2007.07825v1)\n",
      "  Downloading to: downloads/2007.07825v1.pdf\n",
      "0.3105 - Listening while Speaking and Visualizing: Improving ASR through Multimodal Chain (http://arxiv.org/abs/1906.00579v3)\n",
      "  Downloading to: downloads/1906.00579v3.pdf\n",
      "0.2871 - Hierarchical Decision Making by Generating and Following Natural Language Instructions (http://arxiv.org/abs/1906.00744v5)\n",
      "  Downloading to: downloads/1906.00744v5.pdf\n",
      "0.2846 - A Study on Effects of Implicit and Explicit Language Model Information for DBLSTM-CTC Based Handwriting Recognition (http://arxiv.org/abs/2008.01532v1)\n",
      "  Downloading to: downloads/2008.01532v1.pdf\n",
      "0.2744 - The Go Transformer: Natural Language Modeling for Game Play (http://arxiv.org/abs/2007.03500v3)\n",
      "  Downloading to: downloads/2007.03500v3.pdf\n",
      "0.2595 - Applying GPGPU to Recurrent Neural Network Language Model based Fast Network Search in the Real-Time LVCSR (http://arxiv.org/abs/2007.11794v1)\n",
      "  Downloading to: downloads/2007.11794v1.pdf\n",
      "0.2560 - DQI: A Guide to Benchmark Evaluation (http://arxiv.org/abs/2008.03964v1)\n",
      "  Downloading to: downloads/2008.03964v1.pdf\n",
      "0.2448 - From Words to Sentences: A Progressive Learning Approach for Zero-resource Machine Translation with Visual Pivots (http://arxiv.org/abs/1906.00872v1)\n",
      "  Downloading to: downloads/1906.00872v1.pdf\n",
      "0.2404 - Unsupervised Text Generation by Learning from Search (http://arxiv.org/abs/2007.08557v1)\n",
      "  Downloading to: downloads/2007.08557v1.pdf\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 0. Create download directory\n",
    "# ----------------------------------------------------\n",
    "download_dir = \"downloads\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Load an embedding model\n",
    "# ----------------------------------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Get abstract of a given paper\n",
    "# ----------------------------------------------------\n",
    "paper_id = \"2511.20636\"  # example\n",
    "search = arxiv.Search(id_list=[paper_id])\n",
    "paper = list(search.results())[0]\n",
    "target_abstract = paper.summary\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Encode the target paper\n",
    "# ----------------------------------------------------\n",
    "target_emb = model.encode(target_abstract, convert_to_tensor=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Search for candidate papers in the same category\n",
    "# ----------------------------------------------------\n",
    "search_query = \"cat:cs.CL\"  # choose your category\n",
    "results = arxiv.Search(query=search_query, max_results=200)\n",
    "\n",
    "candidate_papers = []\n",
    "candidate_abstracts = []\n",
    "\n",
    "for r in results.results():\n",
    "    if r.entry_id.endswith(paper_id):\n",
    "        continue\n",
    "    candidate_papers.append(r)\n",
    "    candidate_abstracts.append(r.summary)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Encode candidate abstracts\n",
    "# ----------------------------------------------------\n",
    "candidate_embs = model.encode(candidate_abstracts, convert_to_tensor=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Compute similarities\n",
    "# ----------------------------------------------------\n",
    "cos_scores = util.cos_sim(target_emb, candidate_embs)[0]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Get top-k similar papers\n",
    "# ----------------------------------------------------\n",
    "top_k = 10\n",
    "top_results = cos_scores.topk(top_k)\n",
    "\n",
    "print(\"Top similar papers:\\n\")\n",
    "\n",
    "for score, idx in zip(top_results.values, top_results.indices):\n",
    "    p = candidate_papers[idx]\n",
    "    print(f\"{score:.4f} - {p.title} ({p.entry_id})\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 8. Download the PDF\n",
    "    # ----------------------------------------------------\n",
    "    pdf_path = os.path.join(download_dir, f\"{p.get_short_id()}.pdf\")\n",
    "    print(f\"  Downloading to: {pdf_path}\")\n",
    "\n",
    "    p.download_pdf(dirpath=download_dir, filename=f\"{p.get_short_id()}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb2b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
