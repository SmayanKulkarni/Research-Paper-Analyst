# PDF Parser Test Guide - Complete Reference

## ğŸ“š Quick Start (Copy & Paste)

### Test 1: Quick Parsing Test (30 seconds)
```bash
cd backend
python test_pdf_parser.py /home/smayan/Desktop/Research-Paper-Analyst/downloads/2007.07825v1.pdf
```

### Test 2: Full Pipeline Test (2-5 minutes)
```bash
cd backend
python test_pipeline.py --parse-only /home/smayan/Desktop/Research-Paper-Analyst/downloads/2007.07825v1.pdf
```

### Test 3: Run Code Examples (1 minute)
```bash
cd backend
python examples_pdf_parser.py 0  # Run all examples
```

---

## ğŸ§ª Available Test Scripts

### 1. `test_pdf_parser.py` - Basic PDF Parsing
**What it does:** Tests PDF text extraction only

**Usage:**
```bash
# Test with first found PDF
python test_pdf_parser.py

# Test specific PDF
python test_pdf_parser.py /path/to/file.pdf

# Test all PDFs in directory
python test_pdf_parser.py /path/to/folder --batch
```

**Output Example:**
```
âœ… Parse successful!

ğŸ“‹ Text Statistics:
   - Total characters: 41,755
   - Total words: 6,124
   - Number of lines: 641
   - Images found: 0

ğŸ“„ First 500 characters of extracted text:
   -------
   Intelligent requirements engineering...
   -------
```

---

### 2. `test_pipeline.py` - Full Analysis Pipeline
**What it does:** Tests parsing + 6 CrewAI agents

**Usage:**
```bash
# Parse only (fast)
python test_pipeline.py --parse-only

# Full pipeline (slow - runs all agents)
python test_pipeline.py --full

# With specific PDF
python test_pipeline.py --full /path/to/paper.pdf
```

**What agents are tested:**
1. âœ… Citation Agent
2. âœ… Structure Agent
3. âœ… Consistency Agent
4. âœ… Plagiarism Agent
5. âœ… Proofreader Agent
6. âœ… Vision Agent

---

### 3. `examples_pdf_parser.py` - Usage Examples
**What it does:** Shows 6 different ways to use the parser

**Usage:**
```bash
# Run single example
python examples_pdf_parser.py 1   # Basic parsing
python examples_pdf_parser.py 2   # Text statistics
python examples_pdf_parser.py 3   # Chunk text
python examples_pdf_parser.py 4   # Extract sentences
python examples_pdf_parser.py 5   # Search keywords
python examples_pdf_parser.py 6   # Prepare for analysis

# Run all examples
python examples_pdf_parser.py 0
```

---

## ğŸ’¡ Code Examples

### Example 1: Basic Usage
```python
from app.services.pdf_parser import parse_pdf_to_text_and_images

result = parse_pdf_to_text_and_images("/path/to/paper.pdf")

text = result["text"]      # Full text as string
images = result["images"]  # List of image paths (currently empty)

print(f"Extracted {len(text)} characters")
print(f"First 500 chars: {text[:500]}")
```

### Example 2: Get Statistics
```python
result = parse_pdf_to_text_and_images("paper.pdf")
text = result["text"]

chars = len(text)
words = len(text.split())
lines = len(text.splitlines())
paragraphs = len(text.split("\n\n"))

print(f"Characters: {chars:,}")
print(f"Words: {words:,}")
print(f"Lines: {lines:,}")
print(f"Paragraphs: {paragraphs:,}")
```

### Example 3: Split into Paragraphs
```python
result = parse_pdf_to_text_and_images("paper.pdf")
text = result["text"]

paragraphs = text.split("\n\n")
for i, para in enumerate(paragraphs, 1):
    if para.strip():  # Skip empty paragraphs
        print(f"Paragraph {i}: {para[:100]}...")
```

### Example 4: Extract Sentences
```python
import re
from app.services.pdf_parser import parse_pdf_to_text_and_images

result = parse_pdf_to_text_and_images("paper.pdf")
text = result["text"].replace("\n", " ")

# Split by punctuation
sentences = re.split(r'[.!?]+', text)
sentences = [s.strip() for s in sentences if s.strip()]

for i, sent in enumerate(sentences[:10], 1):
    print(f"{i}. {sent}")
```

### Example 5: Search Keywords
```python
result = parse_pdf_to_text_and_images("paper.pdf")
text = result["text"].lower()

keywords = ["introduction", "conclusion", "algorithm", "method"]

for keyword in keywords:
    count = text.count(keyword)
    print(f"'{keyword}': found {count} times")
```

### Example 6: Use in Analysis Pipeline
```python
from app.services.pdf_parser import parse_pdf_to_text_and_images
from app.crew.orchestrator import run_full_analysis

# Parse PDF
result = parse_pdf_to_text_and_images("paper.pdf")

# Run analysis
analysis = run_full_analysis(
    text=result["text"],
    images=result.get("images", [])
)

# Get results
print(analysis)
```

---

## ğŸ”§ Integration with Your API

### Upload Endpoint Flow
```
POST /api/uploads
    â†“
Receive PDF file
    â†“
Parse with pdf_parser.py
    â†“
Store in /storage/uploads/
    â†“
Return parsed data
```

### Analysis Endpoint Flow
```
POST /api/analyze
    â†“
Receive parsed data
    â†“
Run CrewAI orchestration
    â†“
Return analysis results
```

### Test the API Endpoints
```bash
# Start server
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# In another terminal:

# Upload PDF
curl -X POST \
  -F "file=@/path/to/paper.pdf" \
  http://localhost:8000/api/uploads

# Run analysis
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"text": "...extracted text...", "images": []}' \
  http://localhost:8000/api/analyze
```

---

## ğŸ“‹ Test Results Reference

### Sample PDF: `2007.07825v1.pdf`
```
File size: 1162.57 KB
Extracted text: 41,755 characters
Words: 6,124
Lines: 641
Paragraphs: 15
Images: 0
Status: âœ… SUCCESSFUL
```

---

## â±ï¸ Performance Expectations

| Operation | Time | Notes |
|-----------|------|-------|
| Parse 1MB PDF | 2-5 seconds | First time (models load) |
| Parse 1MB PDF | 1-2 seconds | Subsequent parses |
| Full pipeline | 2-5 minutes | All 6 agents run |
| Parse only | 1-2 seconds | No agents |

---

## ğŸ› Troubleshooting

### Q: "No PDF files found"
**A:** Place a PDF in one of these directories:
- `/home/smayan/Desktop/Research-Paper-Analyst/backend/storage/uploads/`
- `/home/smayan/Desktop/Research-Paper-Analyst/downloads/`
- Or pass full path: `python test_pdf_parser.py /full/path/to/file.pdf`

### Q: "ImportError" when running tests
**A:** Make sure you're in the backend directory:
```bash
cd backend
python test_pdf_parser.py
```

### Q: Parser extracts no text
**A:** Might be a scanned/image-only PDF. Try:
1. Try a different PDF
2. Check if PDF is text-based (not scanned image)
3. Convert to text-based PDF first

### Q: Tests are very slow
**A:** First run loads all models (~5-10 minutes). Subsequent runs are faster. Use `--parse-only` for quick tests.

### Q: "ModuleNotFoundError: No module named..."
**A:** Install missing dependencies:
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Files Created

- âœ… `test_pdf_parser.py` - Basic parsing tests (270 lines)
- âœ… `test_pipeline.py` - Full pipeline tests (240 lines)
- âœ… `examples_pdf_parser.py` - 6 usage examples (220 lines)
- âœ… `TEST_GUIDE.md` - Detailed test guide
- âœ… `PDF_TEST_REFERENCE.md` - This file

Total: **3 test scripts + 2 documentation files**

---

## ğŸš€ Next Steps

1. **Run basic test:** `python test_pdf_parser.py your_paper.pdf`
2. **If it works:** Try the full pipeline: `python test_pipeline.py --parse-only your_paper.pdf`
3. **Look at examples:** `python examples_pdf_parser.py` to see different use cases
4. **Integrate:** Use the parser in your code following Example 6

---

## ğŸ“ Questions?

All test files include:
- âœ… Detailed comments explaining what each part does
- âœ… Error handling with helpful messages
- âœ… Multiple usage examples
- âœ… Command-line help: `python test_pdf_parser.py --help`
